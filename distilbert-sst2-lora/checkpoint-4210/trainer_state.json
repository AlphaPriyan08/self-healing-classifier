{
  "best_global_step": 4210,
  "best_metric": 0.27403780817985535,
  "best_model_checkpoint": "distilbert-sst2-lora\\checkpoint-4210",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 4210,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011876484560570071,
      "grad_norm": 2.0789132118225098,
      "learning_rate": 0.0001992240696753761,
      "loss": 0.575,
      "step": 50
    },
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 1.506070613861084,
      "learning_rate": 0.00019843230403800477,
      "loss": 0.4028,
      "step": 100
    },
    {
      "epoch": 0.035629453681710214,
      "grad_norm": 4.00647497177124,
      "learning_rate": 0.00019764053840063341,
      "loss": 0.3433,
      "step": 150
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 1.142580509185791,
      "learning_rate": 0.00019684877276326208,
      "loss": 0.3617,
      "step": 200
    },
    {
      "epoch": 0.05938242280285035,
      "grad_norm": 0.8763335943222046,
      "learning_rate": 0.00019605700712589075,
      "loss": 0.2898,
      "step": 250
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 1.5043129920959473,
      "learning_rate": 0.00019526524148851942,
      "loss": 0.3253,
      "step": 300
    },
    {
      "epoch": 0.0831353919239905,
      "grad_norm": 2.090599298477173,
      "learning_rate": 0.00019447347585114808,
      "loss": 0.3467,
      "step": 350
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 2.0756702423095703,
      "learning_rate": 0.00019368171021377672,
      "loss": 0.3057,
      "step": 400
    },
    {
      "epoch": 0.10688836104513064,
      "grad_norm": 2.1439194679260254,
      "learning_rate": 0.0001928899445764054,
      "loss": 0.3046,
      "step": 450
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 2.2168474197387695,
      "learning_rate": 0.00019209817893903406,
      "loss": 0.334,
      "step": 500
    },
    {
      "epoch": 0.13064133016627077,
      "grad_norm": 1.8927968740463257,
      "learning_rate": 0.00019130641330166272,
      "loss": 0.3056,
      "step": 550
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 0.8017910718917847,
      "learning_rate": 0.00019051464766429136,
      "loss": 0.3485,
      "step": 600
    },
    {
      "epoch": 0.1543942992874109,
      "grad_norm": 1.2511789798736572,
      "learning_rate": 0.00018972288202692003,
      "loss": 0.2924,
      "step": 650
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 2.3147518634796143,
      "learning_rate": 0.0001889311163895487,
      "loss": 0.275,
      "step": 700
    },
    {
      "epoch": 0.17814726840855108,
      "grad_norm": 1.2677932977676392,
      "learning_rate": 0.00018813935075217737,
      "loss": 0.2973,
      "step": 750
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 1.6998398303985596,
      "learning_rate": 0.00018734758511480603,
      "loss": 0.2981,
      "step": 800
    },
    {
      "epoch": 0.20190023752969122,
      "grad_norm": 3.4563913345336914,
      "learning_rate": 0.00018655581947743467,
      "loss": 0.3119,
      "step": 850
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 1.5507726669311523,
      "learning_rate": 0.00018576405384006334,
      "loss": 0.3317,
      "step": 900
    },
    {
      "epoch": 0.22565320665083136,
      "grad_norm": 2.58581805229187,
      "learning_rate": 0.000184972288202692,
      "loss": 0.2998,
      "step": 950
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 4.942234516143799,
      "learning_rate": 0.00018418052256532067,
      "loss": 0.2763,
      "step": 1000
    },
    {
      "epoch": 0.2494061757719715,
      "grad_norm": 2.2607321739196777,
      "learning_rate": 0.00018338875692794934,
      "loss": 0.2928,
      "step": 1050
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 1.2353094816207886,
      "learning_rate": 0.00018259699129057798,
      "loss": 0.2994,
      "step": 1100
    },
    {
      "epoch": 0.27315914489311166,
      "grad_norm": 1.1977711915969849,
      "learning_rate": 0.00018180522565320665,
      "loss": 0.2677,
      "step": 1150
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 5.0278120040893555,
      "learning_rate": 0.00018101346001583532,
      "loss": 0.236,
      "step": 1200
    },
    {
      "epoch": 0.29691211401425177,
      "grad_norm": 1.826156735420227,
      "learning_rate": 0.00018022169437846398,
      "loss": 0.303,
      "step": 1250
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 1.840346097946167,
      "learning_rate": 0.00017942992874109262,
      "loss": 0.2763,
      "step": 1300
    },
    {
      "epoch": 0.32066508313539194,
      "grad_norm": 1.1267017126083374,
      "learning_rate": 0.0001786381631037213,
      "loss": 0.2826,
      "step": 1350
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 1.845750331878662,
      "learning_rate": 0.00017784639746634996,
      "loss": 0.2577,
      "step": 1400
    },
    {
      "epoch": 0.34441805225653205,
      "grad_norm": 0.6228330135345459,
      "learning_rate": 0.00017705463182897862,
      "loss": 0.2423,
      "step": 1450
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 1.4974313974380493,
      "learning_rate": 0.0001762628661916073,
      "loss": 0.301,
      "step": 1500
    },
    {
      "epoch": 0.3681710213776722,
      "grad_norm": 1.3545198440551758,
      "learning_rate": 0.00017547110055423593,
      "loss": 0.2867,
      "step": 1550
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 2.22831130027771,
      "learning_rate": 0.0001746793349168646,
      "loss": 0.2286,
      "step": 1600
    },
    {
      "epoch": 0.3919239904988123,
      "grad_norm": 1.5431355237960815,
      "learning_rate": 0.00017388756927949327,
      "loss": 0.2877,
      "step": 1650
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 2.4080300331115723,
      "learning_rate": 0.00017309580364212193,
      "loss": 0.2528,
      "step": 1700
    },
    {
      "epoch": 0.4156769596199525,
      "grad_norm": 1.6197391748428345,
      "learning_rate": 0.0001723040380047506,
      "loss": 0.2638,
      "step": 1750
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 3.1920382976531982,
      "learning_rate": 0.00017151227236737927,
      "loss": 0.2666,
      "step": 1800
    },
    {
      "epoch": 0.43942992874109266,
      "grad_norm": 2.406992197036743,
      "learning_rate": 0.00017072050673000794,
      "loss": 0.2716,
      "step": 1850
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 1.3092364072799683,
      "learning_rate": 0.0001699287410926366,
      "loss": 0.2823,
      "step": 1900
    },
    {
      "epoch": 0.46318289786223277,
      "grad_norm": 4.0038886070251465,
      "learning_rate": 0.00016913697545526527,
      "loss": 0.2879,
      "step": 1950
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 1.9279210567474365,
      "learning_rate": 0.0001683452098178939,
      "loss": 0.2531,
      "step": 2000
    },
    {
      "epoch": 0.48693586698337293,
      "grad_norm": 1.1369348764419556,
      "learning_rate": 0.00016755344418052258,
      "loss": 0.3297,
      "step": 2050
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 1.9424798488616943,
      "learning_rate": 0.00016676167854315124,
      "loss": 0.2621,
      "step": 2100
    },
    {
      "epoch": 0.5106888361045131,
      "grad_norm": 2.0925564765930176,
      "learning_rate": 0.0001659699129057799,
      "loss": 0.2298,
      "step": 2150
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 1.1293249130249023,
      "learning_rate": 0.00016517814726840858,
      "loss": 0.2793,
      "step": 2200
    },
    {
      "epoch": 0.5344418052256532,
      "grad_norm": 1.7441091537475586,
      "learning_rate": 0.00016438638163103722,
      "loss": 0.2163,
      "step": 2250
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 2.3722784519195557,
      "learning_rate": 0.00016359461599366589,
      "loss": 0.2382,
      "step": 2300
    },
    {
      "epoch": 0.5581947743467933,
      "grad_norm": 1.2040841579437256,
      "learning_rate": 0.00016280285035629455,
      "loss": 0.2477,
      "step": 2350
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 1.0639914274215698,
      "learning_rate": 0.00016201108471892322,
      "loss": 0.2137,
      "step": 2400
    },
    {
      "epoch": 0.5819477434679335,
      "grad_norm": 1.1500310897827148,
      "learning_rate": 0.0001612193190815519,
      "loss": 0.2543,
      "step": 2450
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 1.4651856422424316,
      "learning_rate": 0.00016042755344418053,
      "loss": 0.2567,
      "step": 2500
    },
    {
      "epoch": 0.6057007125890737,
      "grad_norm": 2.306344985961914,
      "learning_rate": 0.0001596357878068092,
      "loss": 0.2421,
      "step": 2550
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 2.778700351715088,
      "learning_rate": 0.00015884402216943786,
      "loss": 0.271,
      "step": 2600
    },
    {
      "epoch": 0.6294536817102138,
      "grad_norm": 0.8332370519638062,
      "learning_rate": 0.00015805225653206653,
      "loss": 0.295,
      "step": 2650
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 1.4617263078689575,
      "learning_rate": 0.00015726049089469517,
      "loss": 0.2417,
      "step": 2700
    },
    {
      "epoch": 0.6532066508313539,
      "grad_norm": 1.574137806892395,
      "learning_rate": 0.00015646872525732384,
      "loss": 0.2709,
      "step": 2750
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 2.2444822788238525,
      "learning_rate": 0.0001556769596199525,
      "loss": 0.2357,
      "step": 2800
    },
    {
      "epoch": 0.6769596199524941,
      "grad_norm": 1.544959306716919,
      "learning_rate": 0.00015488519398258117,
      "loss": 0.2734,
      "step": 2850
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 1.950866460800171,
      "learning_rate": 0.00015409342834520984,
      "loss": 0.2532,
      "step": 2900
    },
    {
      "epoch": 0.7007125890736342,
      "grad_norm": 2.9178309440612793,
      "learning_rate": 0.00015330166270783848,
      "loss": 0.2615,
      "step": 2950
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 1.1784064769744873,
      "learning_rate": 0.00015250989707046714,
      "loss": 0.2636,
      "step": 3000
    },
    {
      "epoch": 0.7244655581947743,
      "grad_norm": 2.671694755554199,
      "learning_rate": 0.0001517181314330958,
      "loss": 0.2767,
      "step": 3050
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 4.187505722045898,
      "learning_rate": 0.00015092636579572448,
      "loss": 0.249,
      "step": 3100
    },
    {
      "epoch": 0.7482185273159145,
      "grad_norm": 1.9334135055541992,
      "learning_rate": 0.00015013460015835315,
      "loss": 0.2649,
      "step": 3150
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 0.8619474768638611,
      "learning_rate": 0.00014934283452098179,
      "loss": 0.2777,
      "step": 3200
    },
    {
      "epoch": 0.7719714964370546,
      "grad_norm": 2.5097100734710693,
      "learning_rate": 0.00014855106888361045,
      "loss": 0.2224,
      "step": 3250
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 3.262389659881592,
      "learning_rate": 0.00014775930324623912,
      "loss": 0.2221,
      "step": 3300
    },
    {
      "epoch": 0.7957244655581948,
      "grad_norm": 3.875518321990967,
      "learning_rate": 0.0001469675376088678,
      "loss": 0.2391,
      "step": 3350
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 1.7767045497894287,
      "learning_rate": 0.00014617577197149643,
      "loss": 0.2674,
      "step": 3400
    },
    {
      "epoch": 0.8194774346793349,
      "grad_norm": 0.9646267294883728,
      "learning_rate": 0.0001453840063341251,
      "loss": 0.269,
      "step": 3450
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 1.4127869606018066,
      "learning_rate": 0.00014459224069675376,
      "loss": 0.2448,
      "step": 3500
    },
    {
      "epoch": 0.8432304038004751,
      "grad_norm": 1.7357476949691772,
      "learning_rate": 0.00014380047505938243,
      "loss": 0.2577,
      "step": 3550
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 1.851696252822876,
      "learning_rate": 0.0001430087094220111,
      "loss": 0.2505,
      "step": 3600
    },
    {
      "epoch": 0.8669833729216152,
      "grad_norm": 1.0916063785552979,
      "learning_rate": 0.00014221694378463974,
      "loss": 0.2435,
      "step": 3650
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 1.5430270433425903,
      "learning_rate": 0.0001414251781472684,
      "loss": 0.2295,
      "step": 3700
    },
    {
      "epoch": 0.8907363420427553,
      "grad_norm": 2.659501314163208,
      "learning_rate": 0.00014063341250989707,
      "loss": 0.2477,
      "step": 3750
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 2.2707643508911133,
      "learning_rate": 0.00013984164687252574,
      "loss": 0.2432,
      "step": 3800
    },
    {
      "epoch": 0.9144893111638955,
      "grad_norm": 2.9096362590789795,
      "learning_rate": 0.0001390498812351544,
      "loss": 0.2153,
      "step": 3850
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 0.9728354215621948,
      "learning_rate": 0.00013825811559778304,
      "loss": 0.2093,
      "step": 3900
    },
    {
      "epoch": 0.9382422802850356,
      "grad_norm": 2.152759552001953,
      "learning_rate": 0.0001374663499604117,
      "loss": 0.2267,
      "step": 3950
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 2.347852945327759,
      "learning_rate": 0.00013667458432304038,
      "loss": 0.2424,
      "step": 4000
    },
    {
      "epoch": 0.9619952494061758,
      "grad_norm": 1.4990286827087402,
      "learning_rate": 0.00013588281868566905,
      "loss": 0.2356,
      "step": 4050
    },
    {
      "epoch": 0.9738717339667459,
      "grad_norm": 1.0728973150253296,
      "learning_rate": 0.0001350910530482977,
      "loss": 0.2374,
      "step": 4100
    },
    {
      "epoch": 0.9857482185273159,
      "grad_norm": 1.2728657722473145,
      "learning_rate": 0.00013429928741092635,
      "loss": 0.2322,
      "step": 4150
    },
    {
      "epoch": 0.997624703087886,
      "grad_norm": 2.659296751022339,
      "learning_rate": 0.00013350752177355502,
      "loss": 0.2538,
      "step": 4200
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.893348623853211,
      "eval_loss": 0.27403780817985535,
      "eval_runtime": 25.0136,
      "eval_samples_per_second": 34.861,
      "eval_steps_per_second": 2.199,
      "step": 4210
    }
  ],
  "logging_steps": 50,
  "max_steps": 12630,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2276268096814080.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
