{
  "best_global_step": 4210,
  "best_metric": 0.27403780817985535,
  "best_model_checkpoint": "distilbert-sst2-lora\\checkpoint-4210",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 8420,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011876484560570071,
      "grad_norm": 2.0789132118225098,
      "learning_rate": 0.0001992240696753761,
      "loss": 0.575,
      "step": 50
    },
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 1.506070613861084,
      "learning_rate": 0.00019843230403800477,
      "loss": 0.4028,
      "step": 100
    },
    {
      "epoch": 0.035629453681710214,
      "grad_norm": 4.00647497177124,
      "learning_rate": 0.00019764053840063341,
      "loss": 0.3433,
      "step": 150
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 1.142580509185791,
      "learning_rate": 0.00019684877276326208,
      "loss": 0.3617,
      "step": 200
    },
    {
      "epoch": 0.05938242280285035,
      "grad_norm": 0.8763335943222046,
      "learning_rate": 0.00019605700712589075,
      "loss": 0.2898,
      "step": 250
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 1.5043129920959473,
      "learning_rate": 0.00019526524148851942,
      "loss": 0.3253,
      "step": 300
    },
    {
      "epoch": 0.0831353919239905,
      "grad_norm": 2.090599298477173,
      "learning_rate": 0.00019447347585114808,
      "loss": 0.3467,
      "step": 350
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 2.0756702423095703,
      "learning_rate": 0.00019368171021377672,
      "loss": 0.3057,
      "step": 400
    },
    {
      "epoch": 0.10688836104513064,
      "grad_norm": 2.1439194679260254,
      "learning_rate": 0.0001928899445764054,
      "loss": 0.3046,
      "step": 450
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 2.2168474197387695,
      "learning_rate": 0.00019209817893903406,
      "loss": 0.334,
      "step": 500
    },
    {
      "epoch": 0.13064133016627077,
      "grad_norm": 1.8927968740463257,
      "learning_rate": 0.00019130641330166272,
      "loss": 0.3056,
      "step": 550
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 0.8017910718917847,
      "learning_rate": 0.00019051464766429136,
      "loss": 0.3485,
      "step": 600
    },
    {
      "epoch": 0.1543942992874109,
      "grad_norm": 1.2511789798736572,
      "learning_rate": 0.00018972288202692003,
      "loss": 0.2924,
      "step": 650
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 2.3147518634796143,
      "learning_rate": 0.0001889311163895487,
      "loss": 0.275,
      "step": 700
    },
    {
      "epoch": 0.17814726840855108,
      "grad_norm": 1.2677932977676392,
      "learning_rate": 0.00018813935075217737,
      "loss": 0.2973,
      "step": 750
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 1.6998398303985596,
      "learning_rate": 0.00018734758511480603,
      "loss": 0.2981,
      "step": 800
    },
    {
      "epoch": 0.20190023752969122,
      "grad_norm": 3.4563913345336914,
      "learning_rate": 0.00018655581947743467,
      "loss": 0.3119,
      "step": 850
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 1.5507726669311523,
      "learning_rate": 0.00018576405384006334,
      "loss": 0.3317,
      "step": 900
    },
    {
      "epoch": 0.22565320665083136,
      "grad_norm": 2.58581805229187,
      "learning_rate": 0.000184972288202692,
      "loss": 0.2998,
      "step": 950
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 4.942234516143799,
      "learning_rate": 0.00018418052256532067,
      "loss": 0.2763,
      "step": 1000
    },
    {
      "epoch": 0.2494061757719715,
      "grad_norm": 2.2607321739196777,
      "learning_rate": 0.00018338875692794934,
      "loss": 0.2928,
      "step": 1050
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 1.2353094816207886,
      "learning_rate": 0.00018259699129057798,
      "loss": 0.2994,
      "step": 1100
    },
    {
      "epoch": 0.27315914489311166,
      "grad_norm": 1.1977711915969849,
      "learning_rate": 0.00018180522565320665,
      "loss": 0.2677,
      "step": 1150
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 5.0278120040893555,
      "learning_rate": 0.00018101346001583532,
      "loss": 0.236,
      "step": 1200
    },
    {
      "epoch": 0.29691211401425177,
      "grad_norm": 1.826156735420227,
      "learning_rate": 0.00018022169437846398,
      "loss": 0.303,
      "step": 1250
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 1.840346097946167,
      "learning_rate": 0.00017942992874109262,
      "loss": 0.2763,
      "step": 1300
    },
    {
      "epoch": 0.32066508313539194,
      "grad_norm": 1.1267017126083374,
      "learning_rate": 0.0001786381631037213,
      "loss": 0.2826,
      "step": 1350
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 1.845750331878662,
      "learning_rate": 0.00017784639746634996,
      "loss": 0.2577,
      "step": 1400
    },
    {
      "epoch": 0.34441805225653205,
      "grad_norm": 0.6228330135345459,
      "learning_rate": 0.00017705463182897862,
      "loss": 0.2423,
      "step": 1450
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 1.4974313974380493,
      "learning_rate": 0.0001762628661916073,
      "loss": 0.301,
      "step": 1500
    },
    {
      "epoch": 0.3681710213776722,
      "grad_norm": 1.3545198440551758,
      "learning_rate": 0.00017547110055423593,
      "loss": 0.2867,
      "step": 1550
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 2.22831130027771,
      "learning_rate": 0.0001746793349168646,
      "loss": 0.2286,
      "step": 1600
    },
    {
      "epoch": 0.3919239904988123,
      "grad_norm": 1.5431355237960815,
      "learning_rate": 0.00017388756927949327,
      "loss": 0.2877,
      "step": 1650
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 2.4080300331115723,
      "learning_rate": 0.00017309580364212193,
      "loss": 0.2528,
      "step": 1700
    },
    {
      "epoch": 0.4156769596199525,
      "grad_norm": 1.6197391748428345,
      "learning_rate": 0.0001723040380047506,
      "loss": 0.2638,
      "step": 1750
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 3.1920382976531982,
      "learning_rate": 0.00017151227236737927,
      "loss": 0.2666,
      "step": 1800
    },
    {
      "epoch": 0.43942992874109266,
      "grad_norm": 2.406992197036743,
      "learning_rate": 0.00017072050673000794,
      "loss": 0.2716,
      "step": 1850
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 1.3092364072799683,
      "learning_rate": 0.0001699287410926366,
      "loss": 0.2823,
      "step": 1900
    },
    {
      "epoch": 0.46318289786223277,
      "grad_norm": 4.0038886070251465,
      "learning_rate": 0.00016913697545526527,
      "loss": 0.2879,
      "step": 1950
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 1.9279210567474365,
      "learning_rate": 0.0001683452098178939,
      "loss": 0.2531,
      "step": 2000
    },
    {
      "epoch": 0.48693586698337293,
      "grad_norm": 1.1369348764419556,
      "learning_rate": 0.00016755344418052258,
      "loss": 0.3297,
      "step": 2050
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 1.9424798488616943,
      "learning_rate": 0.00016676167854315124,
      "loss": 0.2621,
      "step": 2100
    },
    {
      "epoch": 0.5106888361045131,
      "grad_norm": 2.0925564765930176,
      "learning_rate": 0.0001659699129057799,
      "loss": 0.2298,
      "step": 2150
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 1.1293249130249023,
      "learning_rate": 0.00016517814726840858,
      "loss": 0.2793,
      "step": 2200
    },
    {
      "epoch": 0.5344418052256532,
      "grad_norm": 1.7441091537475586,
      "learning_rate": 0.00016438638163103722,
      "loss": 0.2163,
      "step": 2250
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 2.3722784519195557,
      "learning_rate": 0.00016359461599366589,
      "loss": 0.2382,
      "step": 2300
    },
    {
      "epoch": 0.5581947743467933,
      "grad_norm": 1.2040841579437256,
      "learning_rate": 0.00016280285035629455,
      "loss": 0.2477,
      "step": 2350
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 1.0639914274215698,
      "learning_rate": 0.00016201108471892322,
      "loss": 0.2137,
      "step": 2400
    },
    {
      "epoch": 0.5819477434679335,
      "grad_norm": 1.1500310897827148,
      "learning_rate": 0.0001612193190815519,
      "loss": 0.2543,
      "step": 2450
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 1.4651856422424316,
      "learning_rate": 0.00016042755344418053,
      "loss": 0.2567,
      "step": 2500
    },
    {
      "epoch": 0.6057007125890737,
      "grad_norm": 2.306344985961914,
      "learning_rate": 0.0001596357878068092,
      "loss": 0.2421,
      "step": 2550
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 2.778700351715088,
      "learning_rate": 0.00015884402216943786,
      "loss": 0.271,
      "step": 2600
    },
    {
      "epoch": 0.6294536817102138,
      "grad_norm": 0.8332370519638062,
      "learning_rate": 0.00015805225653206653,
      "loss": 0.295,
      "step": 2650
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 1.4617263078689575,
      "learning_rate": 0.00015726049089469517,
      "loss": 0.2417,
      "step": 2700
    },
    {
      "epoch": 0.6532066508313539,
      "grad_norm": 1.574137806892395,
      "learning_rate": 0.00015646872525732384,
      "loss": 0.2709,
      "step": 2750
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 2.2444822788238525,
      "learning_rate": 0.0001556769596199525,
      "loss": 0.2357,
      "step": 2800
    },
    {
      "epoch": 0.6769596199524941,
      "grad_norm": 1.544959306716919,
      "learning_rate": 0.00015488519398258117,
      "loss": 0.2734,
      "step": 2850
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 1.950866460800171,
      "learning_rate": 0.00015409342834520984,
      "loss": 0.2532,
      "step": 2900
    },
    {
      "epoch": 0.7007125890736342,
      "grad_norm": 2.9178309440612793,
      "learning_rate": 0.00015330166270783848,
      "loss": 0.2615,
      "step": 2950
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 1.1784064769744873,
      "learning_rate": 0.00015250989707046714,
      "loss": 0.2636,
      "step": 3000
    },
    {
      "epoch": 0.7244655581947743,
      "grad_norm": 2.671694755554199,
      "learning_rate": 0.0001517181314330958,
      "loss": 0.2767,
      "step": 3050
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 4.187505722045898,
      "learning_rate": 0.00015092636579572448,
      "loss": 0.249,
      "step": 3100
    },
    {
      "epoch": 0.7482185273159145,
      "grad_norm": 1.9334135055541992,
      "learning_rate": 0.00015013460015835315,
      "loss": 0.2649,
      "step": 3150
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 0.8619474768638611,
      "learning_rate": 0.00014934283452098179,
      "loss": 0.2777,
      "step": 3200
    },
    {
      "epoch": 0.7719714964370546,
      "grad_norm": 2.5097100734710693,
      "learning_rate": 0.00014855106888361045,
      "loss": 0.2224,
      "step": 3250
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 3.262389659881592,
      "learning_rate": 0.00014775930324623912,
      "loss": 0.2221,
      "step": 3300
    },
    {
      "epoch": 0.7957244655581948,
      "grad_norm": 3.875518321990967,
      "learning_rate": 0.0001469675376088678,
      "loss": 0.2391,
      "step": 3350
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 1.7767045497894287,
      "learning_rate": 0.00014617577197149643,
      "loss": 0.2674,
      "step": 3400
    },
    {
      "epoch": 0.8194774346793349,
      "grad_norm": 0.9646267294883728,
      "learning_rate": 0.0001453840063341251,
      "loss": 0.269,
      "step": 3450
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 1.4127869606018066,
      "learning_rate": 0.00014459224069675376,
      "loss": 0.2448,
      "step": 3500
    },
    {
      "epoch": 0.8432304038004751,
      "grad_norm": 1.7357476949691772,
      "learning_rate": 0.00014380047505938243,
      "loss": 0.2577,
      "step": 3550
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 1.851696252822876,
      "learning_rate": 0.0001430087094220111,
      "loss": 0.2505,
      "step": 3600
    },
    {
      "epoch": 0.8669833729216152,
      "grad_norm": 1.0916063785552979,
      "learning_rate": 0.00014221694378463974,
      "loss": 0.2435,
      "step": 3650
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 1.5430270433425903,
      "learning_rate": 0.0001414251781472684,
      "loss": 0.2295,
      "step": 3700
    },
    {
      "epoch": 0.8907363420427553,
      "grad_norm": 2.659501314163208,
      "learning_rate": 0.00014063341250989707,
      "loss": 0.2477,
      "step": 3750
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 2.2707643508911133,
      "learning_rate": 0.00013984164687252574,
      "loss": 0.2432,
      "step": 3800
    },
    {
      "epoch": 0.9144893111638955,
      "grad_norm": 2.9096362590789795,
      "learning_rate": 0.0001390498812351544,
      "loss": 0.2153,
      "step": 3850
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 0.9728354215621948,
      "learning_rate": 0.00013825811559778304,
      "loss": 0.2093,
      "step": 3900
    },
    {
      "epoch": 0.9382422802850356,
      "grad_norm": 2.152759552001953,
      "learning_rate": 0.0001374663499604117,
      "loss": 0.2267,
      "step": 3950
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 2.347852945327759,
      "learning_rate": 0.00013667458432304038,
      "loss": 0.2424,
      "step": 4000
    },
    {
      "epoch": 0.9619952494061758,
      "grad_norm": 1.4990286827087402,
      "learning_rate": 0.00013588281868566905,
      "loss": 0.2356,
      "step": 4050
    },
    {
      "epoch": 0.9738717339667459,
      "grad_norm": 1.0728973150253296,
      "learning_rate": 0.0001350910530482977,
      "loss": 0.2374,
      "step": 4100
    },
    {
      "epoch": 0.9857482185273159,
      "grad_norm": 1.2728657722473145,
      "learning_rate": 0.00013429928741092635,
      "loss": 0.2322,
      "step": 4150
    },
    {
      "epoch": 0.997624703087886,
      "grad_norm": 2.659296751022339,
      "learning_rate": 0.00013350752177355502,
      "loss": 0.2538,
      "step": 4200
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.893348623853211,
      "eval_loss": 0.27403780817985535,
      "eval_runtime": 25.0136,
      "eval_samples_per_second": 34.861,
      "eval_steps_per_second": 2.199,
      "step": 4210
    },
    {
      "epoch": 1.009501187648456,
      "grad_norm": 1.6887052059173584,
      "learning_rate": 0.0001327157561361837,
      "loss": 0.208,
      "step": 4250
    },
    {
      "epoch": 1.0213776722090262,
      "grad_norm": 4.268126010894775,
      "learning_rate": 0.00013192399049881235,
      "loss": 0.2354,
      "step": 4300
    },
    {
      "epoch": 1.0332541567695963,
      "grad_norm": 1.863988995552063,
      "learning_rate": 0.00013113222486144102,
      "loss": 0.1997,
      "step": 4350
    },
    {
      "epoch": 1.0451306413301662,
      "grad_norm": 2.748694896697998,
      "learning_rate": 0.0001303404592240697,
      "loss": 0.2361,
      "step": 4400
    },
    {
      "epoch": 1.0570071258907363,
      "grad_norm": 3.355440139770508,
      "learning_rate": 0.00012954869358669836,
      "loss": 0.222,
      "step": 4450
    },
    {
      "epoch": 1.0688836104513064,
      "grad_norm": 1.2629859447479248,
      "learning_rate": 0.00012875692794932702,
      "loss": 0.2001,
      "step": 4500
    },
    {
      "epoch": 1.0807600950118765,
      "grad_norm": 2.466874837875366,
      "learning_rate": 0.0001279651623119557,
      "loss": 0.2314,
      "step": 4550
    },
    {
      "epoch": 1.0926365795724466,
      "grad_norm": 3.813333034515381,
      "learning_rate": 0.00012717339667458433,
      "loss": 0.226,
      "step": 4600
    },
    {
      "epoch": 1.1045130641330165,
      "grad_norm": 2.916712760925293,
      "learning_rate": 0.000126381631037213,
      "loss": 0.222,
      "step": 4650
    },
    {
      "epoch": 1.1163895486935866,
      "grad_norm": 2.5931811332702637,
      "learning_rate": 0.00012558986539984166,
      "loss": 0.1771,
      "step": 4700
    },
    {
      "epoch": 1.1282660332541568,
      "grad_norm": 2.021805763244629,
      "learning_rate": 0.00012479809976247033,
      "loss": 0.236,
      "step": 4750
    },
    {
      "epoch": 1.1401425178147269,
      "grad_norm": 1.035211443901062,
      "learning_rate": 0.00012400633412509897,
      "loss": 0.2036,
      "step": 4800
    },
    {
      "epoch": 1.152019002375297,
      "grad_norm": 3.237774133682251,
      "learning_rate": 0.00012321456848772764,
      "loss": 0.2442,
      "step": 4850
    },
    {
      "epoch": 1.1638954869358669,
      "grad_norm": 1.7116384506225586,
      "learning_rate": 0.0001224228028503563,
      "loss": 0.2284,
      "step": 4900
    },
    {
      "epoch": 1.175771971496437,
      "grad_norm": 0.35444507002830505,
      "learning_rate": 0.00012163103721298496,
      "loss": 0.237,
      "step": 4950
    },
    {
      "epoch": 1.187648456057007,
      "grad_norm": 3.336719512939453,
      "learning_rate": 0.00012083927157561363,
      "loss": 0.2091,
      "step": 5000
    },
    {
      "epoch": 1.1995249406175772,
      "grad_norm": 2.134061336517334,
      "learning_rate": 0.00012004750593824228,
      "loss": 0.2244,
      "step": 5050
    },
    {
      "epoch": 1.2114014251781473,
      "grad_norm": 1.194237470626831,
      "learning_rate": 0.00011925574030087095,
      "loss": 0.2012,
      "step": 5100
    },
    {
      "epoch": 1.2232779097387174,
      "grad_norm": 1.805111289024353,
      "learning_rate": 0.00011846397466349962,
      "loss": 0.1902,
      "step": 5150
    },
    {
      "epoch": 1.2351543942992875,
      "grad_norm": 1.2676500082015991,
      "learning_rate": 0.00011767220902612828,
      "loss": 0.2399,
      "step": 5200
    },
    {
      "epoch": 1.2470308788598574,
      "grad_norm": 2.7902352809906006,
      "learning_rate": 0.00011688044338875695,
      "loss": 0.2069,
      "step": 5250
    },
    {
      "epoch": 1.2589073634204275,
      "grad_norm": 2.776174306869507,
      "learning_rate": 0.00011608867775138559,
      "loss": 0.2155,
      "step": 5300
    },
    {
      "epoch": 1.2707838479809976,
      "grad_norm": 1.9141931533813477,
      "learning_rate": 0.00011529691211401426,
      "loss": 0.1964,
      "step": 5350
    },
    {
      "epoch": 1.2826603325415677,
      "grad_norm": 2.07401704788208,
      "learning_rate": 0.00011450514647664292,
      "loss": 0.2346,
      "step": 5400
    },
    {
      "epoch": 1.2945368171021379,
      "grad_norm": 4.1846513748168945,
      "learning_rate": 0.00011371338083927159,
      "loss": 0.2155,
      "step": 5450
    },
    {
      "epoch": 1.3064133016627077,
      "grad_norm": 1.9090704917907715,
      "learning_rate": 0.00011292161520190023,
      "loss": 0.1937,
      "step": 5500
    },
    {
      "epoch": 1.3182897862232779,
      "grad_norm": 2.28106427192688,
      "learning_rate": 0.0001121298495645289,
      "loss": 0.2403,
      "step": 5550
    },
    {
      "epoch": 1.330166270783848,
      "grad_norm": 1.5405396223068237,
      "learning_rate": 0.00011133808392715757,
      "loss": 0.1784,
      "step": 5600
    },
    {
      "epoch": 1.342042755344418,
      "grad_norm": 2.1938562393188477,
      "learning_rate": 0.00011054631828978623,
      "loss": 0.2157,
      "step": 5650
    },
    {
      "epoch": 1.3539192399049882,
      "grad_norm": 3.04534912109375,
      "learning_rate": 0.0001097545526524149,
      "loss": 0.1991,
      "step": 5700
    },
    {
      "epoch": 1.365795724465558,
      "grad_norm": 0.7520281076431274,
      "learning_rate": 0.00010896278701504354,
      "loss": 0.1874,
      "step": 5750
    },
    {
      "epoch": 1.3776722090261282,
      "grad_norm": 2.4294350147247314,
      "learning_rate": 0.00010817102137767221,
      "loss": 0.175,
      "step": 5800
    },
    {
      "epoch": 1.3895486935866983,
      "grad_norm": 2.053420305252075,
      "learning_rate": 0.00010737925574030087,
      "loss": 0.1997,
      "step": 5850
    },
    {
      "epoch": 1.4014251781472684,
      "grad_norm": 2.9395666122436523,
      "learning_rate": 0.00010658749010292954,
      "loss": 0.2158,
      "step": 5900
    },
    {
      "epoch": 1.4133016627078385,
      "grad_norm": 1.19590163230896,
      "learning_rate": 0.00010579572446555821,
      "loss": 0.2138,
      "step": 5950
    },
    {
      "epoch": 1.4251781472684084,
      "grad_norm": 2.496837615966797,
      "learning_rate": 0.00010500395882818685,
      "loss": 0.2016,
      "step": 6000
    },
    {
      "epoch": 1.4370546318289787,
      "grad_norm": 0.9936047196388245,
      "learning_rate": 0.00010421219319081552,
      "loss": 0.1866,
      "step": 6050
    },
    {
      "epoch": 1.4489311163895486,
      "grad_norm": 1.283408284187317,
      "learning_rate": 0.00010342042755344418,
      "loss": 0.2348,
      "step": 6100
    },
    {
      "epoch": 1.4608076009501187,
      "grad_norm": 0.40601444244384766,
      "learning_rate": 0.00010262866191607285,
      "loss": 0.2066,
      "step": 6150
    },
    {
      "epoch": 1.4726840855106889,
      "grad_norm": 5.098232269287109,
      "learning_rate": 0.0001018368962787015,
      "loss": 0.1882,
      "step": 6200
    },
    {
      "epoch": 1.484560570071259,
      "grad_norm": 2.045429229736328,
      "learning_rate": 0.00010104513064133017,
      "loss": 0.2174,
      "step": 6250
    },
    {
      "epoch": 1.496437054631829,
      "grad_norm": 3.3194737434387207,
      "learning_rate": 0.00010025336500395884,
      "loss": 0.2156,
      "step": 6300
    },
    {
      "epoch": 1.508313539192399,
      "grad_norm": 2.5942766666412354,
      "learning_rate": 9.94615993665875e-05,
      "loss": 0.2005,
      "step": 6350
    },
    {
      "epoch": 1.520190023752969,
      "grad_norm": 7.183286190032959,
      "learning_rate": 9.866983372921616e-05,
      "loss": 0.2094,
      "step": 6400
    },
    {
      "epoch": 1.5320665083135392,
      "grad_norm": 1.3929953575134277,
      "learning_rate": 9.787806809184483e-05,
      "loss": 0.1778,
      "step": 6450
    },
    {
      "epoch": 1.5439429928741093,
      "grad_norm": 2.7600700855255127,
      "learning_rate": 9.708630245447348e-05,
      "loss": 0.238,
      "step": 6500
    },
    {
      "epoch": 1.5558194774346794,
      "grad_norm": 2.467780590057373,
      "learning_rate": 9.629453681710215e-05,
      "loss": 0.2133,
      "step": 6550
    },
    {
      "epoch": 1.5676959619952493,
      "grad_norm": 0.9412243366241455,
      "learning_rate": 9.55027711797308e-05,
      "loss": 0.1674,
      "step": 6600
    },
    {
      "epoch": 1.5795724465558196,
      "grad_norm": 1.623233437538147,
      "learning_rate": 9.471100554235947e-05,
      "loss": 0.2122,
      "step": 6650
    },
    {
      "epoch": 1.5914489311163895,
      "grad_norm": 0.48481249809265137,
      "learning_rate": 9.391923990498813e-05,
      "loss": 0.1787,
      "step": 6700
    },
    {
      "epoch": 1.6033254156769596,
      "grad_norm": 5.730860710144043,
      "learning_rate": 9.312747426761679e-05,
      "loss": 0.2037,
      "step": 6750
    },
    {
      "epoch": 1.6152019002375297,
      "grad_norm": 3.804394245147705,
      "learning_rate": 9.233570863024546e-05,
      "loss": 0.2197,
      "step": 6800
    },
    {
      "epoch": 1.6270783847980996,
      "grad_norm": 2.2673659324645996,
      "learning_rate": 9.154394299287411e-05,
      "loss": 0.2093,
      "step": 6850
    },
    {
      "epoch": 1.63895486935867,
      "grad_norm": 2.8252837657928467,
      "learning_rate": 9.075217735550278e-05,
      "loss": 0.2226,
      "step": 6900
    },
    {
      "epoch": 1.6508313539192399,
      "grad_norm": 0.45517247915267944,
      "learning_rate": 8.996041171813143e-05,
      "loss": 0.2052,
      "step": 6950
    },
    {
      "epoch": 1.66270783847981,
      "grad_norm": 1.432106852531433,
      "learning_rate": 8.91686460807601e-05,
      "loss": 0.2037,
      "step": 7000
    },
    {
      "epoch": 1.67458432304038,
      "grad_norm": 2.4109299182891846,
      "learning_rate": 8.837688044338876e-05,
      "loss": 0.1732,
      "step": 7050
    },
    {
      "epoch": 1.68646080760095,
      "grad_norm": 0.878419816493988,
      "learning_rate": 8.758511480601742e-05,
      "loss": 0.1601,
      "step": 7100
    },
    {
      "epoch": 1.6983372921615203,
      "grad_norm": 0.9106056690216064,
      "learning_rate": 8.679334916864608e-05,
      "loss": 0.2368,
      "step": 7150
    },
    {
      "epoch": 1.7102137767220902,
      "grad_norm": 2.190723419189453,
      "learning_rate": 8.600158353127474e-05,
      "loss": 0.1991,
      "step": 7200
    },
    {
      "epoch": 1.7220902612826603,
      "grad_norm": 2.1304259300231934,
      "learning_rate": 8.52098178939034e-05,
      "loss": 0.2328,
      "step": 7250
    },
    {
      "epoch": 1.7339667458432304,
      "grad_norm": 2.0825417041778564,
      "learning_rate": 8.441805225653206e-05,
      "loss": 0.2024,
      "step": 7300
    },
    {
      "epoch": 1.7458432304038005,
      "grad_norm": 0.4094597399234772,
      "learning_rate": 8.362628661916073e-05,
      "loss": 0.1984,
      "step": 7350
    },
    {
      "epoch": 1.7577197149643706,
      "grad_norm": 2.499983549118042,
      "learning_rate": 8.28345209817894e-05,
      "loss": 0.1765,
      "step": 7400
    },
    {
      "epoch": 1.7695961995249405,
      "grad_norm": 3.5041539669036865,
      "learning_rate": 8.204275534441806e-05,
      "loss": 0.2011,
      "step": 7450
    },
    {
      "epoch": 1.7814726840855108,
      "grad_norm": 2.151693820953369,
      "learning_rate": 8.125098970704671e-05,
      "loss": 0.2122,
      "step": 7500
    },
    {
      "epoch": 1.7933491686460807,
      "grad_norm": 3.658637762069702,
      "learning_rate": 8.045922406967538e-05,
      "loss": 0.2294,
      "step": 7550
    },
    {
      "epoch": 1.8052256532066508,
      "grad_norm": 1.9355175495147705,
      "learning_rate": 7.966745843230405e-05,
      "loss": 0.1584,
      "step": 7600
    },
    {
      "epoch": 1.817102137767221,
      "grad_norm": 1.2331641912460327,
      "learning_rate": 7.88756927949327e-05,
      "loss": 0.2167,
      "step": 7650
    },
    {
      "epoch": 1.8289786223277908,
      "grad_norm": 2.7249934673309326,
      "learning_rate": 7.808392715756137e-05,
      "loss": 0.2206,
      "step": 7700
    },
    {
      "epoch": 1.8408551068883612,
      "grad_norm": 0.15607717633247375,
      "learning_rate": 7.729216152019004e-05,
      "loss": 0.1958,
      "step": 7750
    },
    {
      "epoch": 1.852731591448931,
      "grad_norm": 0.8223128318786621,
      "learning_rate": 7.650039588281869e-05,
      "loss": 0.1756,
      "step": 7800
    },
    {
      "epoch": 1.8646080760095012,
      "grad_norm": 2.9714980125427246,
      "learning_rate": 7.570863024544736e-05,
      "loss": 0.2135,
      "step": 7850
    },
    {
      "epoch": 1.8764845605700713,
      "grad_norm": 1.859053611755371,
      "learning_rate": 7.491686460807601e-05,
      "loss": 0.189,
      "step": 7900
    },
    {
      "epoch": 1.8883610451306412,
      "grad_norm": 1.7552367448806763,
      "learning_rate": 7.412509897070468e-05,
      "loss": 0.2225,
      "step": 7950
    },
    {
      "epoch": 1.9002375296912115,
      "grad_norm": 4.097362518310547,
      "learning_rate": 7.333333333333333e-05,
      "loss": 0.1738,
      "step": 8000
    },
    {
      "epoch": 1.9121140142517814,
      "grad_norm": 1.64601731300354,
      "learning_rate": 7.2541567695962e-05,
      "loss": 0.2005,
      "step": 8050
    },
    {
      "epoch": 1.9239904988123515,
      "grad_norm": 1.992457389831543,
      "learning_rate": 7.174980205859067e-05,
      "loss": 0.2038,
      "step": 8100
    },
    {
      "epoch": 1.9358669833729216,
      "grad_norm": 0.4499535858631134,
      "learning_rate": 7.095803642121932e-05,
      "loss": 0.1776,
      "step": 8150
    },
    {
      "epoch": 1.9477434679334917,
      "grad_norm": 3.0309481620788574,
      "learning_rate": 7.016627078384799e-05,
      "loss": 0.1886,
      "step": 8200
    },
    {
      "epoch": 1.9596199524940618,
      "grad_norm": 0.5589901804924011,
      "learning_rate": 6.937450514647664e-05,
      "loss": 0.2117,
      "step": 8250
    },
    {
      "epoch": 1.9714964370546317,
      "grad_norm": 0.7805600762367249,
      "learning_rate": 6.858273950910531e-05,
      "loss": 0.198,
      "step": 8300
    },
    {
      "epoch": 1.9833729216152018,
      "grad_norm": 3.6170284748077393,
      "learning_rate": 6.779097387173396e-05,
      "loss": 0.192,
      "step": 8350
    },
    {
      "epoch": 1.995249406175772,
      "grad_norm": 2.048706293106079,
      "learning_rate": 6.699920823436263e-05,
      "loss": 0.1741,
      "step": 8400
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8956422018348624,
      "eval_loss": 0.30484503507614136,
      "eval_runtime": 24.9017,
      "eval_samples_per_second": 35.018,
      "eval_steps_per_second": 2.209,
      "step": 8420
    }
  ],
  "logging_steps": 50,
  "max_steps": 12630,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4552536193628160.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
